{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/Users/wy/spark-1.6.0-bin-hadoop2.6')\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"myAppName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn import tree\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def evalution(y_test,predict):\n",
    "    labelAndprediction = zip(list(y_test),list(predict))\n",
    "    recallBase = 0\n",
    "    recallUper = 0\n",
    "    precisionBase = 0\n",
    "    precisionUper = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    for label,prediction in labelAndprediction:\n",
    "        label = int(label)\n",
    "        if label == 1 :\n",
    "            recallBase += 1\n",
    "            if prediction == 1 :\n",
    "                recallUper += 1\n",
    "    recall = float(recallUper)/float(recallBase)\n",
    "\n",
    "    for label,prediction in labelAndprediction:\n",
    "        prediction = int(prediction)\n",
    "        if prediction == 1 :\n",
    "            precisionBase += 1\n",
    "            if label == 1 :\n",
    "                precisionUper += 1\n",
    "    precision = float(precisionUper)/float(precisionBase)\n",
    "\n",
    "    for label,prediction in labelAndprediction:\n",
    "        if label == prediction:\n",
    "            accuracy += 1\n",
    "    accuracy = float(accuracy)/float(len(y_test))\n",
    "    f1score = (2*precision*recall)/(precision+recall)\n",
    "\n",
    "    print \"accuracy : %f \" %(accuracy)\n",
    "    print \"recallBase : %f , recallUper : %f , recall : %f \" %(recallBase, recallUper, recall)\n",
    "    print \"precisionBase : %f , precisionUper : %f , precision : %f \" %(precisionBase, precisionUper, precision)\n",
    "    print \"f1score : %f \" %(f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25)\n",
    "dataset = np.column_stack((X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "broadcastVar = sc.broadcast(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_estimators = sc.parallelize(range(10),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadDataset = broadcastVar.value\n",
    "n_estimators.map(lambda x : pallDecisiontree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pallDecisiontree(max_features=\"auto\"):\n",
    "\n",
    "    broadDataset = broadcastVar.value\n",
    "    m,n = broadDataset.shape\n",
    "    # 扣掉label\n",
    "    n = n-1\n",
    "    print m\n",
    "    print n\n",
    "\n",
    "    if max_features == 'auto':\n",
    "        n_features = n\n",
    "    elif max_features == 'sqrt':\n",
    "        n_features = int(math.ceil(np.sqrt(n)))\n",
    "    elif type(max_features).__name__=='float':\n",
    "        n_features =  int(math.ceil(n*max_features))\n",
    "    else:\n",
    "        print \"max_features error\"\n",
    "        \n",
    "    sampleRindex = list(set(np.random.randint(m-1, size=m)))\n",
    "    redRindex = list(set(range(m)).difference(set(sampleRindex)))\n",
    "    featureRindex = list(set(random.sample(range(n), n_features)))\n",
    "    datasetR = dataset[sampleRindex][:, featureRindex]\n",
    "    labelR = dataset[sampleRindex][:, -1]\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(datasetR, labelR)     \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "forest = n_estimators.map(lambda x : pallDecisiontree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "forestList = forest.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predictRF(forest, X_test):\n",
    "    predict_2darray = []\n",
    "    for treeIndex in range(len(forest)):\n",
    "        predict_2darray.append(forest[treeIndex].predict(X_test))\n",
    "    predict_2darray = np.array(predict_2darray)\n",
    "\n",
    "    y_predict = []\n",
    "    for a in range(len(X_test)):\n",
    "        c = Counter(predict_2darray[:,a])\n",
    "        constance = c.most_common(1)[0][0]\n",
    "        p = c.most_common(1)[0][1]/float(len(predict_2darray[:,a]))\n",
    "        y_predict.append(int(constance))\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_predict = predictRF(forestList, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.973684 \n",
      "recallBase : 15.000000 , recallUper : 15.000000 , recall : 1.000000 \n",
      "precisionBase : 16.000000 , precisionUper : 15.000000 , precision : 0.937500 \n",
      "f1score : 0.967742 \n"
     ]
    }
   ],
   "source": [
    "evalution(y_test,y_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
